{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 16:22:41.137613: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-08 16:22:41.625049: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from pytorch_trainer.dataloaders import create_dataloaders\n",
    "from pytorch_trainer.engine import train\n",
    "from pathlib import Path\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                        transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_val_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_val_data_count = len(train_val_data)\n",
    "train_count = int(train_val_data_count * 0.8)\n",
    "val_count = train_val_data_count - train_count\n",
    "train_data, val_data = torch.utils.data.random_split(train_val_data, [train_count, val_count])\n",
    "\n",
    "train_data.classes = train_val_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "    shuffle=True # shuffle data every epoch?\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(val_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SE_Block(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SE_Block, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMALL_CNN(nn.Module):\n",
    "    def __init__(self, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3),\n",
    "        nn.BatchNorm2d(5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        #output 111x111x11\n",
    "\n",
    "        SE_Block(channel=5, reduction=16),\n",
    "\n",
    "        nn.Conv2d(in_channels=5, out_channels=11, kernel_size=3),\n",
    "        nn.BatchNorm2d(11),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Dropout(dropout)\n",
    "        #54x54x22\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=11 * 6 * 6, out_features=100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(in_features=100, out_features=50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(in_features=50, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._body(x)\n",
    "        x = self._head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = SMALL_CNN(dropout=0.2)\n",
    "optimizer = torch.optim.Adam(model_1.parameters(),\n",
    "                            lr=1e-3,\n",
    "                            betas=(0.9,0.999),\n",
    "                            weight_decay=0.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /opt/anaconda3/envs/pytorch_cuda_11.8/lib/python3.11/site-packages/ipykernel_launcher/20240308-162336', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mHyperparameters: \u001b[0mepochs=1000, image_size=(3, 32, 32), batch_size=16, optimizer=Adam, lr=0.001, betas=(0.9, 0.999), weight_decay=0.1, loss=CrossEntropyLoss, scheduler=ReduceLROnPlateau, es_paitence=10, es_min_delta=0, device=cuda\n",
      "\u001b[34m\u001b[1mModel Structure: \u001b[0m\n",
      "=============================================================================================================================\n",
      "Layer (type (var_name))                       Input Shape          Output Shape         Param #              Trainable\n",
      "=============================================================================================================================\n",
      "SMALL_CNN (SMALL_CNN)                         [1, 3, 32, 32]       [1, 10]              --                   True\n",
      "├─Sequential (_body)                          [1, 3, 32, 32]       [1, 11, 6, 6]        --                   True\n",
      "│    └─Conv2d (0)                             [1, 3, 32, 32]       [1, 5, 30, 30]       140                  True\n",
      "│    └─BatchNorm2d (1)                        [1, 5, 30, 30]       [1, 5, 30, 30]       10                   True\n",
      "│    └─ReLU (2)                               [1, 5, 30, 30]       [1, 5, 30, 30]       --                   --\n",
      "│    └─MaxPool2d (3)                          [1, 5, 30, 30]       [1, 5, 15, 15]       --                   --\n",
      "│    └─SE_Block (4)                           [1, 5, 15, 15]       [1, 5, 15, 15]       --                   --\n",
      "│    │    └─AdaptiveAvgPool2d (avg_pool)      [1, 5, 15, 15]       [1, 5, 1, 1]         --                   --\n",
      "│    │    └─Sequential (fc)                   [1, 5]               [1, 5]               --                   --\n",
      "│    └─Conv2d (5)                             [1, 5, 15, 15]       [1, 11, 13, 13]      506                  True\n",
      "│    └─BatchNorm2d (6)                        [1, 11, 13, 13]      [1, 11, 13, 13]      22                   True\n",
      "│    └─ReLU (7)                               [1, 11, 13, 13]      [1, 11, 13, 13]      --                   --\n",
      "│    └─MaxPool2d (8)                          [1, 11, 13, 13]      [1, 11, 6, 6]        --                   --\n",
      "│    └─Dropout (9)                            [1, 11, 6, 6]        [1, 11, 6, 6]        --                   --\n",
      "├─Sequential (_head)                          [1, 11, 6, 6]        [1, 10]              --                   True\n",
      "│    └─Flatten (0)                            [1, 11, 6, 6]        [1, 396]             --                   --\n",
      "│    └─Linear (1)                             [1, 396]             [1, 100]             39,700               True\n",
      "│    └─ReLU (2)                               [1, 100]             [1, 100]             --                   --\n",
      "│    └─Dropout (3)                            [1, 100]             [1, 100]             --                   --\n",
      "│    └─Linear (4)                             [1, 100]             [1, 50]              5,050                True\n",
      "│    └─ReLU (5)                               [1, 50]              [1, 50]              --                   --\n",
      "│    └─Dropout (6)                            [1, 50]              [1, 50]              --                   --\n",
      "│    └─Linear (7)                             [1, 50]              [1, 10]              510                  True\n",
      "=============================================================================================================================\n",
      "Total params: 45,938\n",
      "Trainable params: 45,938\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 0.26\n",
      "=============================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.10\n",
      "Params size (MB): 0.18\n",
      "Estimated Total Size (MB): 0.30\n",
      "=============================================================================================================================\n",
      "Image sizes (3, 32, 32) train, validation and test\n",
      "Logging results to \u001b[1m/opt/anaconda3/envs/pytorch_cuda_11.8/lib/python3.11/site-packages/ipykernel_launcher/20240308-162336\u001b[0m\n",
      "Starting SMALL_CNN training on dataset of 40000 images with 10 classes for 1000 epochs...\n",
      "\n",
      "     Epoch   GPU mem  Train Loss   Train Acc    Val loss     Val Acc    ES Count\n",
      "    1/1000   0.0252G        2.02          19%          2       20.3%     Start      : 100%|██████████| 2500/2500 [00:08<00:00, 285.02it/s]\n",
      "    2/1000   0.0252G        1.99        19.3%       1.98         20%     Start      : 100%|██████████| 2500/2500 [00:08<00:00, 288.97it/s]\n",
      "    3/1000   0.0252G        1.99        19.2%       2.04       17.6%      1/10      : 100%|██████████| 2500/2500 [00:08<00:00, 288.82it/s]\n",
      "    4/1000   0.0252G        1.99        19.9%       2.01       17.9%      2/10      : 100%|██████████| 2500/2500 [00:08<00:00, 288.10it/s]\n",
      "    5/1000   0.0252G        1.99        19.9%       1.99       19.2%      3/10      : 100%|██████████| 2500/2500 [00:08<00:00, 288.27it/s]\n",
      "    6/1000   0.0252G        1.99        19.9%       2.28       12.7%      4/10      : 100%|██████████| 2500/2500 [00:08<00:00, 288.95it/s]\n",
      "    7/1000   0.0252G        1.98        19.7%       2.12       15.8%      5/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.70it/s]\n",
      "    8/1000   0.0252G        1.98        20.1%       1.96       20.1%     Start      : 100%|██████████| 2500/2500 [00:08<00:00, 287.61it/s]\n",
      "    9/1000   0.0252G        1.99          20%       2.01       19.9%      1/10      : 100%|██████████| 2500/2500 [00:08<00:00, 287.61it/s]\n",
      "   10/1000   0.0252G        1.99        19.9%       2.51       11.8%      2/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.06it/s]\n",
      "   11/1000   0.0252G        1.98        19.9%       2.08       17.5%      3/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.83it/s]\n",
      "   12/1000   0.0252G        1.98        20.1%       1.95       18.7%     Start      : 100%|██████████| 2500/2500 [00:08<00:00, 284.31it/s]\n",
      "   13/1000   0.0252G        1.98          20%       2.05       19.2%      1/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.24it/s]\n",
      "   14/1000   0.0252G        1.98        20.1%       2.67       10.6%      2/10      : 100%|██████████| 2500/2500 [00:08<00:00, 287.94it/s]\n",
      "   15/1000   0.0252G        1.99          20%       2.07       16.8%      3/10      : 100%|██████████| 2500/2500 [00:08<00:00, 291.48it/s]\n",
      "   16/1000   0.0252G        1.99        20.2%       2.02       19.2%      4/10      : 100%|██████████| 2500/2500 [00:08<00:00, 292.74it/s]\n",
      "   17/1000   0.0252G        1.98        20.2%       2.07       18.3%      5/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.37it/s]\n",
      "   18/1000   0.0252G        1.98        20.2%       1.95       20.2%     Start      : 100%|██████████| 2500/2500 [00:08<00:00, 286.19it/s]\n",
      "   19/1000   0.0252G        1.98        20.3%       2.03       17.9%      1/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.41it/s]\n",
      "   20/1000   0.0252G        1.99        19.9%          2       18.4%      2/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.32it/s]\n",
      "   21/1000   0.0252G        1.99        20.2%          2       20.8%      3/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.53it/s]\n",
      "   22/1000   0.0252G        1.98        20.2%       2.06       18.5%      4/10      : 100%|██████████| 2500/2500 [00:08<00:00, 288.04it/s]\n",
      "   23/1000   0.0252G        1.98        20.3%       2.06       16.8%      5/10      : 100%|██████████| 2500/2500 [00:08<00:00, 287.11it/s]\n",
      "   24/1000   0.0252G        1.98        20.6%       2.32       12.4%      6/10      : 100%|██████████| 2500/2500 [00:08<00:00, 285.98it/s]\n",
      "   25/1000   0.0252G        1.98        20.7%       1.95       21.9%     Start      : 100%|██████████| 2500/2500 [00:08<00:00, 288.12it/s]\n",
      "   26/1000   0.0252G        1.98        20.1%       1.97       19.5%      1/10      : 100%|██████████| 2500/2500 [00:08<00:00, 297.69it/s]\n",
      "   27/1000   0.0252G        1.98        20.7%       2.05       19.2%      2/10      : 100%|██████████| 2500/2500 [00:08<00:00, 292.06it/s]\n",
      "   28/1000   0.0252G        1.98        20.6%       2.12       16.7%      3/10      : 100%|██████████| 2500/2500 [00:08<00:00, 287.19it/s]\n",
      "   29/1000   0.0252G        1.98        20.3%       1.99       23.1%      4/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.18it/s]\n",
      "   30/1000   0.0252G        1.98        20.4%       1.95       19.6%      5/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.04it/s]\n",
      "   31/1000   0.0252G        1.98        20.3%       1.99       18.6%      6/10      : 100%|██████████| 2500/2500 [00:08<00:00, 285.84it/s]\n",
      "   32/1000   0.0252G        1.98        20.3%       1.96       19.3%      7/10      : 100%|██████████| 2500/2500 [00:08<00:00, 284.94it/s]\n",
      "   33/1000   0.0252G        1.98        20.5%       2.03       17.3%      8/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.66it/s]\n",
      "   34/1000   0.0252G        1.98        20.3%       1.94       22.1%     Start      : 100%|██████████| 2500/2500 [00:08<00:00, 286.17it/s]\n",
      "   35/1000   0.0252G        1.98        20.3%       1.97       20.7%      1/10      : 100%|██████████| 2500/2500 [00:08<00:00, 286.30it/s]\n",
      "   36/1000   0.0252G        1.98        20.3%       2.38       13.6%      2/10      : 100%|██████████| 2500/2500 [00:08<00:00, 285.52it/s]\n",
      "   37/1000   0.0252G        1.98        20.5%       2.09       15.6%      3/10      : 100%|██████████| 2500/2500 [00:08<00:00, 285.75it/s]\n",
      "   38/1000   0.0252G        1.98        20.5%       1.97       21.9%      4/10      : 100%|██████████| 2500/2500 [00:08<00:00, 285.22it/s]\n",
      "   39/1000   0.0252G        1.98        20.4%       2.07       15.8%      5/10      : 100%|██████████| 2500/2500 [00:08<00:00, 285.44it/s]\n",
      "   40/1000   0.0252G        1.98        20.5%       2.14       15.8%      6/10      : 100%|██████████| 2500/2500 [00:08<00:00, 285.02it/s]\n",
      "   41/1000   0.0252G        1.98        20.2%       2.28       13.1%      7/10      : 100%|██████████| 2500/2500 [00:08<00:00, 284.81it/s]\n",
      "   42/1000   0.0252G        1.98        20.4%       2.04         18%      8/10      : 100%|██████████| 2500/2500 [00:08<00:00, 285.34it/s]\n",
      "   43/1000   0.0252G        1.98        20.2%        2.1       17.1%      9/10      : 100%|██████████| 2500/2500 [00:08<00:00, 284.53it/s]\n",
      "   44/1000   0.0252G        1.98        20.3%       2.11       16.6%     10/10      : 100%|██████████| 2500/2500 [00:08<00:00, 284.39it/s]\n",
      "Plotting Graphs for Model\n",
      "\u001b[34m\u001b[1mTest Model: \u001b[0mloading best model with val acc of 23.13% and val loss of 0.2313\n",
      "Making predictions: 100%|██████████| 625/625 [00:00<00:00, 635.25it/s]\n",
      "\u001b[34m\u001b[1mFinal Result: \u001b[0mepochs=1000, val_acc=23.13%, test_acc=17.16%, test_loss=2.100073853302002, date=2024-03-08T16:30:01.184861\n",
      "\u001b[34m\u001b[1mAccuracy: \u001b[0m17.16%\n",
      "------------------------------------------------------- Finished ------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model_1,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    test_dataloader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    EPOCHS,\n",
    "    early_stopper_paitence=10,\n",
    "    scheduler=scheduler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92e67d5ffbed6dc58e9f7fa1e06c72a68fbdda23e0cf40b8f772bb6639a6f8df"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 ('pytorch_cuda_11.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
